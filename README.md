# ðŸ©º CTG Classification â€” Datathon 2025

## ðŸ“˜ Overview
This project was developed for **Datathon 2025**, focusing on the detection and classification of **Cardiotocography (CTG)** scans into three fetal health states:

- **Normal (0)** â€” Healthy fetal state  
- **Suspect (1)** â€” Potential warning signals  
- **Pathologic (2)** â€” Fetal distress  

The goal is to design an automated pipeline that can process raw CTG data, clean and standardize it, train multiple ML models, and evaluate their performance in identifying fetal health conditions.

## ðŸ§­ Repository Structure

> Datathon-2025/ \
â”‚ \
â”œâ”€â”€ README.md \
â”œâ”€â”€ report.docx â† Academic report (methodology + findings)
â”‚
â”œâ”€â”€ data_exploration/
â”‚ â”œâ”€â”€ ctg_exploration.ipynb â† Exploratory data analysis & visualization
â”‚ â””â”€â”€ ctg_cleaning.py â† Data preprocessing & feature scaling
â”‚
â”œâ”€â”€ training/
â”‚ â””â”€â”€ train_model.py â† Main model training script
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ nn_model.pt â† Saved neural net weights
â”‚ â”œâ”€â”€ rf_model.pt â† Saved RandomForest weights
â”‚ â””â”€â”€ scaler.pkl â† Fitted StandardScaler for inference
â”‚
â”œâ”€â”€ inference/
â”‚ â””â”€â”€ inference.py â† Predicts fetal state on new CTG samples
â”‚
â””â”€â”€ misc/
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ feature_importance.png
â””â”€â”€ model_comparison.csv


## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

> git clone https://github.com/Glitzyclub/Datathon-2025.git
>
> cd Datathon-2025

### 2ï¸âƒ£ Install Dependencies

> pip install -r requirements.txt

## ðŸš€ How to Run
### ðŸ§¹ Step 1: Data Exploration
Open the notebook:

> data_exploration/ctg_exploration.ipynb

This file performs:

- Data visualization and feature analysis
- Correlation heatmaps
- Missing value checks
- Skew correction and scaling

### ðŸ§  Step 2: Train Models

> python training/train_model.py

This script:

- Cleans and scales the CTG dataset
- Trains multiple models (Logistic Regression, Random Forest, XGBoost, LightGBM, CatBoost, Neural Net)
- Evaluates each using:
  - Balanced Accuracy
  - Macro F1 Score
- Saves the best-performing models under /models/.

### ðŸ”Ž Step 3: Run Inference
Once trained, test the model on new unseen data:

> python inference/inference.py

This script:

- Loads the saved model and scaler
- Processes new CTG samples
- Outputs predicted fetal states (0 = Normal, 1 = Suspect, 2 = Pathologic)

## ðŸ“Š Model Performance Summary
|  Model	|  Balanced Accuracy	| Macro F1 | Key Observation |
| --------|---------------------|----------|-----------------|
| Logistic Regression |	0.87	| 0.86	| Good interpretability |
| Random Forest |	0.97 |	0.98	| Strong overall performance |
| XGBoost |	0.96	|  0.97	| Slightly better minority class handling |
| Neural Net (MLP) |	0.74 |	0.78 |	Underperforms due to data imbalance |

## ðŸ’¡ Insights
Most false negatives occur when Suspect cases are predicted as Normal, aligning with real-world clinical ambiguity.

Tree-based models (RF, XGB) outperform the neural net on limited data.

Logistic Regression provides interpretability, aiding in explainable AI reporting.



